{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve all the relevant data from the table athletic-data in the database.\n",
    "# Pre-requisite :\n",
    "  1. Activity has to be of more than 2hrs.\n",
    "  2. Watts and HeartRate column should not be null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-03T23:34:41.657748Z",
     "start_time": "2024-01-03T23:34:32.765741Z"
    }
   },
   "outputs": [],
   "source": [
    "%reset\n",
    "import pandas as pd\n",
    "\n",
    "from src.config.LoadProperties import retrieve_data_sql\n",
    "from src.repositories.PowerAndHRRepository import configs, sql_engine\n",
    "year = 2021\n",
    "athlete_id = 863203\n",
    "\n",
    "\"\"\"\n",
    "Read and return athletic data from a SQL database.\n",
    "\n",
    ":return: A pandas DataFrame containing the athletic data.\n",
    "\"\"\"\n",
    "\n",
    "def get_athletic_data(id, activity_year):\n",
    "    sql = retrieve_data_sql.replace(\"(athlete_id)\",str(id)+\")\").replace(\"(year)\",str(activity_year))\n",
    "    return pd.read_sql(sql, sql_engine)\n",
    "\n",
    "\n",
    "athletic_data_db = get_athletic_data(athlete_id, year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PROFILING : Removing irrelevant columns not required for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_ignore = configs.get(\"ignore-columns\").data\n",
    "athletic_data = athletic_data_db.drop(cols_to_ignore.split(\",\"), axis=1).rename(columns={'watts' : 'power'})\n",
    "athletic_data['distance'] = athletic_data['distance'].apply(lambda x: [float(value) for value in x])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Check if the lengths of lists in specified columns are the same for each row\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def check_lengths(row):\n",
    "    columns_to_check = ['distance', 'heartrate', 'power', 'time']\n",
    "    lengths = [len(row[col]) for col in columns_to_check]\n",
    "    return all(length == lengths[0] for length in lengths)\n",
    "\n",
    "# Apply the function to each row and count the activity IDs with different lengths\n",
    "result = athletic_data[athletic_data.apply(check_lengths, axis=1)]\n",
    "count_different_lengths = len(athletic_data) - len(result)\n",
    "\n",
    "print(f\"Count of activity IDs with different lengths: {count_different_lengths}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# NA/NONE CHECK : Checking if watts or heartrate column contains null values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "hr_contains_none = athletic_data['heartrate'].apply(lambda x: any(pd.isna(item) for item in x) if pd.notna(x) else False).sum()\n",
    "print(f\"{hr_contains_none}/{len(athletic_data['heartrate'])} entries contains NA/NONE/null in heartrate\")\n",
    "watts_contains_none =  athletic_data['power'].apply(lambda x: any(pd.isna(item) for item in x) if pd.notna(x) else False).sum()\n",
    "print(f\"{watts_contains_none}/{len(athletic_data['power'])}  entries contains NA/NONE/null in Power\")\n",
    "distance_contains_none =  athletic_data['distance'].apply(lambda x: any(pd.isna(item) for item in x) if pd.notna(x) else False).sum()\n",
    "print(f\"{distance_contains_none}/{len(athletic_data['distance'])}  entries contains NA/NONE/null in Distance\")\n",
    "time_contains_none =  athletic_data['time'].apply(lambda x: any(pd.isna(item) for item in x) if pd.notna(x) else False).sum()\n",
    "print(f\"{time_contains_none}/{len(athletic_data['time'])}  entries contains NA/NONE/null in Time\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cluster view of how long the NA/None/Null entries exists."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "athletic_data_with_na = pd.DataFrame(index=athletic_data['activity_id'], columns=range(len(max(athletic_data['power'], key=len))))\n",
    " \n",
    "\n",
    "for idx, powers in zip(athletic_data['activity_id'], athletic_data['power']):\n",
    "    athletic_data_with_na.loc[idx, :len(powers) - 1] = pd.Series(powers).isna().values\n",
    "\n",
    "athletic_data_with_na = athletic_data_with_na.astype(float)\n",
    "\n",
    "cmap = sns.color_palette(['#00FF00', '#FF0000'])\n",
    "\n",
    "# Create a line plot with color gradient\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.heatmap(data=athletic_data_with_na, cmap=cmap, cbar=False, xticklabels=False) \n",
    "plt.title('Visualization of NA/None/Null Values in Power Column')\n",
    "plt.xlabel('Activity Length(in seconds)')\n",
    "plt.ylabel('Activity ID')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Visualization of the length of NA/None/Null Values in Power Column"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from itertools import groupby\n",
    "from collections import Counter\n",
    "\n",
    "cons_na_pow_list = athletic_data['power'].apply(lambda x: [0] + [len(list(g)) for k, g in groupby(x) if pd.isna(k)]).tolist()\n",
    "\n",
    "def count_occurrences(na_list):\n",
    "    flat_list = [min(num, 60) for sublist in na_list for num in sublist if num != 0]\n",
    "    occurrences = Counter(flat_list)\n",
    "    return dict(occurrences)\n",
    "\n",
    "seq_na_occ_count = count_occurrences(cons_na_pow_list)\n",
    "\n",
    "plt.figure(figsize=(30, 12))\n",
    "\n",
    "plt.bar(seq_na_occ_count.keys(), seq_na_occ_count.values(), color='blue', edgecolor='black')\n",
    "\n",
    "for key, value in seq_na_occ_count.items():\n",
    "    plt.text(key, value, str(value), ha='center', va='bottom')\n",
    "\n",
    "\n",
    "plt.title('Occurrence Count Histogram')\n",
    "plt.xlabel('Consecutive Time(in seconds)')\n",
    "plt.ylabel('Sequential NA Occurrence Count') \n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Interpolation : Applying Linear Interpolation only for NA/None occurring for maximum 5 seconds in the power data recorded."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "li_na = 5\n",
    "def linear_interpolate_na(seq):\n",
    "    interpolate_df = pd.DataFrame({'power': seq})\n",
    "\n",
    "    interpolated_seq = interpolate_df.interpolate(limit=li_na)\n",
    "\n",
    "    return interpolated_seq['power'].tolist()\n",
    "\n",
    "interpolated_power = [linear_interpolate_na(seq) for seq in athletic_data['power']]"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Adding Index column of segment starting index\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "athletic_data['power_ip'] = interpolated_power\n",
    "\n",
    "athletic_data['power_ip_na_adjusted'] = athletic_data['power_ip'].apply(lambda x: [x[i] for i in range(len(x)) if pd.notna(x[i])])\n",
    "\n",
    "#list_a = [1, 4, 5, None, None, None, 4, 5, 9, None, 4, 5, None, None, 3, 8, 10, None]\n",
    "#[1, 4, 5, 4, 5, 9, 4, 5, 3, 8, 10]\n",
    "#[0, 1, 2, 6, 7, 8, 10, 11, 14, 15, 16]\n",
    "#[0, 3, 6, 8]\n",
    "#list_ax = [None, 1, 4, 5, None, None, None, 4, 5, None, 2, 3, 9, None, None, 3, 8, 10, None]\n",
    "#[1, 4, 5, 4, 5, 2, 3, 9, 3, 8, 10]\n",
    "#[1, 2, 3, 7, 8, 10, 11, 12, 15, 16, 17]\n",
    "#[0, 3, 5, 8]\n",
    "def find_segment_start_indices(original_list):\n",
    "    non_none_indices = [i for i, val in enumerate(original_list) if pd.notna(val)]\n",
    "\n",
    "    indexes = []\n",
    "    for i in range(0, len(non_none_indices)):\n",
    "        if i == 0  and non_none_indices[i] >= 0:\n",
    "            indexes.append(i)\n",
    "        if non_none_indices[i] > non_none_indices[i-1] + 1:\n",
    "            indexes.append(i)\n",
    "    return indexes\n",
    " \n",
    "athletic_data['segment_start_index'] = athletic_data.apply(lambda row: find_segment_start_indices(row['power_ip']), axis=1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# NA Replacement Check"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import groupby\n",
    "\n",
    "cons_na_len = 7\n",
    "athletic_data['cons_na_power'] = athletic_data['power'].apply(lambda x: [0] + [len(list(g)) for k, g in groupby(x) if pd.isna(k)])\n",
    "\n",
    "rows_with_cons_na = athletic_data[athletic_data['cons_na_power'].apply(lambda x: cons_na_len in x)]\n",
    "\n",
    "if not rows_with_cons_na.empty:\n",
    "    athletic_ids_with_na = rows_with_cons_na['activity_id'].tolist()\n",
    "    print(f\"Activity IDs with {cons_na_len} consecutive NAs: {athletic_ids_with_na}\")\n",
    "else:\n",
    "    print(\"No rows with \"+ cons_na_len + \"consecutive NAs found.\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Position of the NA in the power list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "activity_id_to_extract = 6399104761\n",
    "\n",
    "selected_activity = athletic_data[athletic_data['activity_id'] == activity_id_to_extract]\n",
    "\n",
    "orig_power_df = pd.DataFrame({'power': selected_activity['power'].iloc[0]})\n",
    "power_df_ip = pd.DataFrame({'power_ip': selected_activity['power_ip'].iloc[0]})\n",
    "power_ip_na_adjusted = pd.DataFrame({'power_ip_na_adjusted': selected_activity['power_ip_na_adjusted'].iloc[0]})\n",
    "segment_index = pd.DataFrame({'segment_start_index': selected_activity['segment_start_index'].iloc[0]})\n",
    "NA_comparison_df =  pd.concat([orig_power_df, power_df_ip, power_ip_na_adjusted, segment_index], axis=1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Choosing the longest continuous segments of each of the rides"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def find_longest_segment_indices(lst):\n",
    "    if not lst:\n",
    "        return [None, None]\n",
    "\n",
    "    start_index, end_index = 0, 0\n",
    "    current_start, current_end = 0, 0\n",
    "    max_length = 1\n",
    "\n",
    "    for i in range(1, len(lst)):\n",
    "        if lst[i] == lst[i - 1] + 1:\n",
    "            current_end = i\n",
    "        else:\n",
    "            current_start = i\n",
    "            current_end = i\n",
    "\n",
    "        current_length = current_end - current_start + 1\n",
    "\n",
    "        if current_length > max_length:\n",
    "            start_index, end_index = current_start, current_end\n",
    "            max_length = current_length\n",
    "\n",
    "    return [start_index, end_index]\n",
    "\n",
    "athletic_data['longest_time_segment'] = athletic_data['time'].apply(find_longest_segment_indices)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Calculating datapoints of all the activities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "get_list_length = lambda x: len(x) if isinstance(x, list) else 0\n",
    "\n",
    "athletic_data['datapoints'] = athletic_data['power'].apply(get_list_length)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Converting Dataframe into CSV for further analysis in MATLAB"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(athletic_data)\n",
    "\n",
    "athlete_name=\"Connor Swift\"\n",
    "athlete_id=\"863203\"\n",
    "year=2021\n",
    "\n",
    "csv_directory = f'Strava Data/{athlete_name}'\n",
    "csv_path = f'{csv_directory}/{athlete_name}_{athlete_id}_{year}.csv'\n",
    "\n",
    "if not os.path.exists(csv_directory):\n",
    "    os.makedirs(csv_directory)\n",
    "\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "\n",
    "print(f\"DataFrame has been successfully converted to CSV and saved at: {csv_path}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve all the relevant data from the table athletic-data in the database.\n",
    "# Pre-requisite :\n",
    "  1. Activity has to be of more than 2hrs.\n",
    "  2. Watts and HeartRate column should not be null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T19:39:40.435082Z",
     "start_time": "2023-12-22T19:39:32.917077Z"
    }
   },
   "outputs": [],
   "source": [
    "%reset\n",
    "from src.repositories.PowerAndHRRepository import configs,get_athletic_data\n",
    "\n",
    "athletic_data_db = get_athletic_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PROFILING : Removing irrelevant columns not required for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T19:39:41.651221Z",
     "start_time": "2023-12-22T19:39:41.076146Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_to_ignore = configs.get(\"ignore-columns\").data\n",
    "athletic_data = athletic_data_db.drop(cols_to_ignore.split(\",\"), axis=1).rename(columns={'watts' : 'power'})\n",
    "athletic_data['distance'] = athletic_data['distance'].apply(lambda x: [float(value) for value in x])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Check if the lengths of lists in specified columns are the same for each row\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of activity IDs with different lengths: 0\n"
     ]
    }
   ],
   "source": [
    "def check_lengths(row):\n",
    "    columns_to_check = ['distance', 'heartrate', 'power', 'time']\n",
    "    lengths = [len(row[col]) for col in columns_to_check]\n",
    "    return all(length == lengths[0] for length in lengths)\n",
    "\n",
    "# Apply the function to each row and count the activity IDs with different lengths\n",
    "result = athletic_data[athletic_data.apply(check_lengths, axis=1)]\n",
    "count_different_lengths = len(athletic_data) - len(result)\n",
    "\n",
    "# Display the count of activity IDs with different lengths\n",
    "print(f\"Count of activity IDs with different lengths: {count_different_lengths}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T19:39:43.351468Z",
     "start_time": "2023-12-22T19:39:43.303061Z"
    }
   },
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "source": [
    "# NA/NONE CHECK : Checking if watts or heartrate column contains null values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/251 entries contains NA/NONE/null in heartrate\n",
      "225/251  entries contains NA/NONE/null in Power\n",
      "0/251  entries contains NA/NONE/null in Distance\n",
      "0/251  entries contains NA/NONE/null in Time\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hr_contains_none = athletic_data['heartrate'].apply(lambda x: any(item is None for item in x) if x is not None else False).sum()\n",
    "print(f\"{hr_contains_none}/{len(athletic_data['heartrate'])} entries contains NA/NONE/null in heartrate\")\n",
    "watts_contains_none =  athletic_data['power'].apply(lambda x: any(item is None for item in x) if x is not None else False).sum()\n",
    "print(f\"{watts_contains_none}/{len(athletic_data['power'])}  entries contains NA/NONE/null in Power\")\n",
    "distance_contains_none =  athletic_data['distance'].apply(lambda x: any(item is None for item in x) if x is not None else False).sum()\n",
    "print(f\"{distance_contains_none}/{len(athletic_data['distance'])}  entries contains NA/NONE/null in Distance\")\n",
    "time_contains_none =  athletic_data['time'].apply(lambda x: any(item is None for item in x) if x is not None else False).sum()\n",
    "print(f\"{time_contains_none}/{len(athletic_data['time'])}  entries contains NA/NONE/null in Time\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T19:39:46.344764Z",
     "start_time": "2023-12-22T19:39:46.065900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LINEAR INTERPOLATION For Missing Data in Power:\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def interpolate_power(lst):\n",
    "    interpolated_lst = []\n",
    "    x = []\n",
    "    y = []\n",
    "    for i, val in enumerate(lst):\n",
    "        if val is None:\n",
    "            x.append(i)\n",
    "        else:\n",
    "            y.append(val)\n",
    "            if len(x) > 0:\n",
    "                interpolated_y = np.interp(x, [x[0] - 1, i], [y[0], val])\n",
    "                interpolated_lst.extend(interpolated_y)\n",
    "                x = []\n",
    "                y = []\n",
    "                interpolated_lst.append(val)\n",
    "            else:\n",
    "                interpolated_lst.append(val)\n",
    "    return interpolated_lst\n",
    "\n",
    "\n",
    "athletic_data['power'] = athletic_data['power'].apply(interpolate_power)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T19:39:49.495429Z",
     "start_time": "2023-12-22T19:39:49.379385Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Converting Dataframe into CSV for further analysis in MATLAB"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame has been successfully converted to CSV and saved at: Strava Data/Connor Swift/Connor Swift_863203_2023.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(athletic_data)\n",
    "\n",
    "# Specify the path where you want to save the CSV file\n",
    "athlete_name=\"Connor Swift\"\n",
    "athlete_id=\"863203\"\n",
    "year=2023\n",
    "\n",
    "csv_directory = f'Strava Data/{athlete_name}'\n",
    "csv_path = f'{csv_directory}/{athlete_name}_{athlete_id}_{year}.csv'\n",
    "\n",
    "# Check if the directory exists, and create it if it doesn't\n",
    "if not os.path.exists(csv_directory):\n",
    "    os.makedirs(csv_directory)\n",
    "\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "\n",
    "print(f\"DataFrame has been successfully converted to CSV and saved at: {csv_path}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T21:49:00.536155Z",
     "start_time": "2023-12-22T21:48:58.767296Z"
    }
   },
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Overview of all the activities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     activity_id activity_date  activity_distance activity_duration  \\\n",
      "0     8347686401    2023-01-06             154.85          05:17:00   \n",
      "1     8337030492    2023-01-04             137.66          04:57:19   \n",
      "2     8325251213    2023-01-02              45.42          01:26:21   \n",
      "3     8331509693    2023-01-03             171.71          05:07:08   \n",
      "4     8358936408    2023-01-08             170.52          05:01:46   \n",
      "..           ...           ...                ...               ...   \n",
      "246  10353025591    2023-12-09             155.49          04:39:11   \n",
      "247  10332032228    2023-12-05             137.47          04:08:44   \n",
      "248  10377762027    2023-12-13             155.47          04:56:55   \n",
      "249  10217566499    2023-11-14              87.49          02:53:51   \n",
      "250  10359289709    2023-12-10             184.79          05:17:14   \n",
      "\n",
      "                                              distance  \\\n",
      "0    [1204.1, 1212.1, 1219.8, 1227.2, 1234.7, 1242....   \n",
      "1    [539.7, 546.1, 552.5, 559.4, 565.3, 571.3, 576...   \n",
      "2    [535.3, 543.4, 551.4, 559.8, 568.2, 576.6, 586...   \n",
      "3    [1187.4, 1195.6, 1204.6, 1212.9, 1221.3, 1230....   \n",
      "4    [1199.1, 1208.0, 1216.3, 1224.5, 1232.6, 1241....   \n",
      "..                                                 ...   \n",
      "246  [303.2, 310.5, 317.6, 325.4, 332.7, 340.0, 347...   \n",
      "247  [357.6, 365.7, 373.0, 380.1, 387.4, 395.3, 403...   \n",
      "248  [99.2, 106.3, 112.9, 119.8, 127.3, 134.7, 141....   \n",
      "249  [306.2, 313.6, 319.7, 326.2, 333.2, 340.9, 348...   \n",
      "250  [94.7, 101.4, 108.0, 114.8, 121.5, 128.7, 136....   \n",
      "\n",
      "                                             heartrate  \\\n",
      "0    [105, 104, 104, 104, 104, 104, 105, 105, 105, ...   \n",
      "1    [115, 115, 114, 114, 113, 111, 110, 108, 107, ...   \n",
      "2    [111, 111, 112, 112, 113, 113, 113, 113, 113, ...   \n",
      "3    [128, 128, 128, 129, 128, 127, 127, 127, 127, ...   \n",
      "4    [129, 129, 129, 129, 129, 129, 128, 128, 128, ...   \n",
      "..                                                 ...   \n",
      "246  [100, 101, 102, 102, 102, 102, 102, 101, 101, ...   \n",
      "247  [107, 107, 108, 110, 111, 112, 113, 114, 114, ...   \n",
      "248  [94, 94, 95, 95, 96, 97, 97, 98, 99, 99, 100, ...   \n",
      "249  [105, 104, 104, 103, 102, 102, 102, 103, 104, ...   \n",
      "250  [86, 89, 90, 92, 93, 94, 94, 95, 96, 97, 97, 9...   \n",
      "\n",
      "                                                 power  \\\n",
      "0    [186, 191, 160, 203, 195, 198, 207, 182, 158, ...   \n",
      "1    [75, 75, 75, 0, 0, 0, 0, 0, 131, 328, 311, 292...   \n",
      "2    [154, 115, 135, 123, 109, 111, 73, 88, 61, 170...   \n",
      "3    [243, 242, 276, 270, 278, 278, 278, 284, 277, ...   \n",
      "4    [257, 250, 246, 266, 256, 261, 261, 265, 266, ...   \n",
      "..                                                 ...   \n",
      "246  [177, 120, 121, 165, 180, 196, 146, 154, 188, ...   \n",
      "247  [232, 182, 166, 164, 139, 169, 217, 203, 173, ...   \n",
      "248  [149, 171, 127, 220, 175, 182, 53, 53, 45, 278...   \n",
      "249  [7, 7, 154, 232, 214, 198, 158, 138, 92, 92, 3...   \n",
      "250  [157, 129, 140, 170, 176, 178, 89, 85, 183, 14...   \n",
      "\n",
      "                                                  time  datapoints  \n",
      "0    [180, 181, 182, 183, 184, 185, 186, 187, 188, ...       18579  \n",
      "1    [88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 9...       17566  \n",
      "2    [90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, ...        4929  \n",
      "3    [177, 178, 179, 180, 181, 182, 183, 184, 185, ...       18115  \n",
      "4    [169, 170, 171, 172, 173, 174, 175, 176, 177, ...       17801  \n",
      "..                                                 ...         ...  \n",
      "246  [181, 182, 183, 184, 185, 186, 187, 188, 189, ...       16677  \n",
      "247  [67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 7...       14841  \n",
      "248  [17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 2...       17726  \n",
      "249  [51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 6...       10373  \n",
      "250  [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 3...       18967  \n",
      "\n",
      "[251 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# Function to get the length of a list\n",
    "get_list_length = lambda x: len(x) if isinstance(x, list) else 0\n",
    "\n",
    "# Apply the function to create new columns\n",
    "athletic_data['datapoints'] = athletic_data['power'].apply(get_list_length)\n",
    "\n",
    "\n",
    "print(athletic_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T19:39:59.867734Z",
     "start_time": "2023-12-22T19:39:59.859711Z"
    }
   },
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Choosing the longest continuous segments of each of the rides"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def find_longest_segment_indices(lst):\n",
    "    if not lst:\n",
    "        return [None, None]\n",
    "\n",
    "    start_index, end_index = 0, 0\n",
    "    current_start, current_end = 0, 0\n",
    "    max_length = 1\n",
    "\n",
    "    for i in range(1, len(lst)):\n",
    "        if lst[i] == lst[i - 1] + 1:\n",
    "            current_end = i\n",
    "        else:\n",
    "            current_start = i\n",
    "            current_end = i\n",
    "\n",
    "        current_length = current_end - current_start + 1\n",
    "\n",
    "        if current_length > max_length:\n",
    "            start_index, end_index = current_start, current_end\n",
    "            max_length = current_length\n",
    "\n",
    "    return [start_index, end_index]\n",
    "\n",
    "athletic_data['longest_time_segment'] = athletic_data['time'].apply(find_longest_segment_indices)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T21:07:55.561441Z",
     "start_time": "2023-12-22T21:07:55.211237Z"
    }
   },
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Please ignore everything else below from here :\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# NON-LINEAR/POLYNOMIAL REGRESSION For Missing Data :\n",
    "#1. Power output/watts has similar variations as heartrate and heartrate has no missing entries(so model can rely on heartrate as the attribute to understand variations for watts and fill missing values.\n",
    "#2. Power Output changes gradually on change of heart rate, not instantaneously.\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import numpy as np\n",
    "\n",
    "def flatten_list(lst):\n",
    "    flattened = []\n",
    "    for item in lst:\n",
    "        if isinstance(item, (list, tuple)):\n",
    "            flattened.extend(flatten_list(item))\n",
    "        else:\n",
    "            flattened.append(item)\n",
    "    return flattened\n",
    "\n",
    "def convert_arrays_to_lists(arr):\n",
    "    converted = []\n",
    "    for item in arr:\n",
    "        if isinstance(item, np.ndarray):\n",
    "            converted.append(item.tolist())\n",
    "        elif isinstance(item, (list, tuple)):\n",
    "            converted.append(convert_arrays_to_lists(item))\n",
    "        else:\n",
    "            converted.append(item)\n",
    "    return converted\n",
    "\n",
    "def fill_none_with_regression(df, degree=2):\n",
    "    df_copy = df.copy()\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    # Prepare the training data\n",
    "    for idx, row in df_copy.iterrows():\n",
    "        heartrate = row['heartrate']\n",
    "        watts = row['watts']\n",
    "        mask = [w is not None for w in watts]  # Create a mask for non-None values\n",
    "        watts_valid = np.array(watts)[mask]\n",
    "        heartrate_valid = np.array(heartrate)[mask]\n",
    "        X_train.extend([[x] for x in heartrate_valid])\n",
    "        y_train.extend([[y] for y in watts_valid])\n",
    "    # Perform polynomial regression\n",
    "    poly_features = PolynomialFeatures(degree=degree)\n",
    "    X_poly = poly_features.fit_transform(X_train)\n",
    "    regressor = LinearRegression()\n",
    "    regressor.fit(X_poly, y_train)\n",
    "    # Fill the missing values\n",
    "    for idx, row in df.iterrows():\n",
    "        heartrate = row['heartrate']\n",
    "        watts = row['watts']\n",
    "        mask = [w is None or w == 0 for w in watts]  # Create a mask for None and 0 values\n",
    "        if any(mask):\n",
    "            heartrate_fill = np.array(heartrate)[mask].reshape(-1, 1)\n",
    "            X_test = poly_features.transform(heartrate_fill)\n",
    "            watts_fill = regressor.predict(X_test)\n",
    "            # Replace the None and 0 values with the predicted values\n",
    "            for i, value in enumerate(watts_fill):\n",
    "                if watts[i] is None or watts[i] == 0:\n",
    "                    watts[i] = value\n",
    "            # Flatten the list of watts and convert arrays to lists\n",
    "            watts_flat = flatten_list(watts)\n",
    "            watts_flat = convert_arrays_to_lists(watts_flat)\n",
    "            df.at[idx, 'watts'] = watts_flat\n",
    "    return df\n",
    "ad_filled = fill_none_with_regression(athletic_data, degree=2)\n",
    "print(ad_filled)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# NOISE REDUCTION : Using Kalman Filtering Technique\n",
    "\n",
    "from pykalman import KalmanFilter\n",
    "\n",
    "def reduce_noise_kalman(data):\n",
    "    kf = KalmanFilter(transition_matrices=[1],\n",
    "                      observation_matrices=[1],\n",
    "                      initial_state_mean=data[0],\n",
    "                      initial_state_covariance=1,\n",
    "                      observation_covariance=1,\n",
    "                      transition_covariance=0.1)\n",
    "\n",
    "    filtered_state_means, filtered_state_covariances = kf.filter(data)\n",
    "\n",
    "    return filtered_state_means\n",
    "\n",
    "athletic_data['heartrate'] = athletic_data['heartrate'].apply(reduce_noise_kalman)\n",
    "athletic_data['watts'] = athletic_data['watts'].apply(reduce_noise_kalman)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DATA DOWNSAMPLING : A data aggregation procedure where we decreasing the time-frequency of the data to plot on graph and visualise easily with less variations and minimizing abundance of values to process, making machine learning algorithms work faster.\n",
    "\n",
    "# Function to downsample a column with None values\n",
    "def downsample_column(arr, factor):\n",
    "    downsampled_arr = []\n",
    "    for i in range(0, len(arr), factor):\n",
    "        segment = arr[i:i+factor]  # Extract a segment of the array based on the downsampling factor\n",
    "        non_none_values = [value for value in segment if value is not None]  # Filter out None values\n",
    "        if non_none_values:\n",
    "            downsampled_arr.append(sum(non_none_values) / len(non_none_values))  # Calculate the average of non-None values\n",
    "        else:\n",
    "            downsampled_arr.append(None)  # Assign None if all values in the segment are None\n",
    "    return downsampled_arr\n",
    "\n",
    "\n",
    "athletic_data['heartrate'] = athletic_data['heartrate'].apply(lambda arr: downsample_column(arr,200))\n",
    "athletic_data['power'] = athletic_data['power'].apply(lambda arr: downsample_column(arr,200))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Saving Preprocessed DataSet : athletic_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%store athletic_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve all the relevant data from the table athletic-data in the database.\n",
    "# Pre-requisite :\n",
    "  1. Activity has to be of more than 2hrs.\n",
    "  2. Watts and HeartRate column should not be null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T00:00:09.648224Z",
     "start_time": "2023-06-05T00:00:01.952947Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are successfully connected to your Database!\n"
     ]
    }
   ],
   "source": [
    "from src.repositories.PowerAndHRRepository import *\n",
    "\n",
    "athletic_data_db = get_athletic_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PROFILING : Removing irrelevant columns not required for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T00:00:09.654397Z",
     "start_time": "2023-06-05T00:00:09.651874Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_to_ignore = configs.get(\"ignore-columns\").data\n",
    "athletic_data = athletic_data_db.drop(cols_to_ignore.split(\",\"), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# NA/NONE CHECK : Checking if watts or heartrate column contains null values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/164 entries contains NA/NONE/null in heartrate\n",
      "147/164  entries contains NA/NONE/null in watts\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "hr_contains_none = athletic_data['heartrate'].apply(lambda x: None in x or np.nan in x or x is None).sum()\n",
    "print(f\"{hr_contains_none}/{len(athletic_data['heartrate'])} entries contains NA/NONE/null in heartrate\")\n",
    "watts_contains_none = athletic_data['watts'].apply(lambda x: None in x or np.nan in x or x is None).sum()\n",
    "print(f\"{watts_contains_none}/{len(athletic_data['watts'])}  entries contains NA/NONE/null in watts\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-05T00:00:12.683573Z",
     "start_time": "2023-06-05T00:00:12.582528Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# NON-LINEAR/POLYNOMIAL REGRESSION For Missing Data :\n",
    "1. Power output/watts has similar variations as heartrate and heartrate has no missing entries(so model can rely on heartrate as the attribute to understand variations for watts and fill missing values.\n",
    "2. Power Output changes gradually on change of heart rate, not instantaneously."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     activity_id                                          heartrate  \\\n",
      "0     8681129847  [83, 85, 86, 85, 85, 85, 85, 84, 83, 82, 80, 7...   \n",
      "1     9039302926  [103, 104, 104, 104, 103, 103, 104, 104, 104, ...   \n",
      "2     8807954766  [109, 109, 108, 108, 108, 107, 106, 107, 107, ...   \n",
      "3     8702957363  [83, 82, 82, 82, 78, 76, 74, 72, 74, 76, 77, 8...   \n",
      "4     8847871051  [111, 110, 109, 108, 108, 108, 108, 108, 106, ...   \n",
      "..           ...                                                ...   \n",
      "159   9095632721  [58, 61, 62, 65, 66, 68, 69, 72, 73, 74, 75, 7...   \n",
      "160   9145237366  [68, 70, 73, 74, 75, 76, 76, 76, 76, 76, 76, 7...   \n",
      "161   8718709606  [83, 84, 85, 87, 87, 90, 92, 93, 95, 96, 98, 9...   \n",
      "162   8816718510  [97, 99, 101, 100, 99, 98, 98, 98, 98, 97, 98,...   \n",
      "163   8757238016  [88, 89, 91, 92, 94, 95, 92, 91, 93, 94, 94, 9...   \n",
      "\n",
      "                                                 watts  \n",
      "0    [21, 21, 21, 36, 36, 6, [117.03046332262377], ...  \n",
      "1    [229, 232, 226, 223, 223, 206, 268, 289, 299, ...  \n",
      "2    [240, 236, 235, 212, 199, 214, 214, 199, 211, ...  \n",
      "3    [[135.34836459202873], [132.71038489235696], [...  \n",
      "4    [76, 150, 219, 187, 198, 49, [181.271989206903...  \n",
      "..                                                 ...  \n",
      "159  [[71.51253821877148], [78.9403341105232], [81....  \n",
      "160  [254, 188, 94, 136, 121, 122, 132, 154, 164, 1...  \n",
      "161  [175, 220, 401, 473, 42, 68, 58, 180, 306, 306...  \n",
      "162  [132, 133, 138, 172, 147, 176, 206, 120, 143, ...  \n",
      "163  [28, 184, 197, 211, 201, 284, 284, 216, 194, 1...  \n",
      "\n",
      "[164 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "def flatten_list(lst):\n",
    "    flattened = []\n",
    "    for item in lst:\n",
    "        if isinstance(item, (list, tuple)):\n",
    "            flattened.extend(item)\n",
    "        else:\n",
    "            flattened.append(item)\n",
    "    return flattened\n",
    "\n",
    "def convert_arrays_to_lists(arr):\n",
    "    converted = []\n",
    "    for item in arr:\n",
    "        if isinstance(item, np.ndarray):\n",
    "            converted.append(item.tolist())\n",
    "        elif isinstance(item, (list, tuple)):\n",
    "            converted.append(convert_arrays_to_lists(item))\n",
    "        else:\n",
    "            converted.append(item)\n",
    "    return converted\n",
    "\n",
    "def fill_none_with_regression(df, degree=2):\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "\n",
    "    # Prepare the training data\n",
    "    for idx, row in df_copy.iterrows():\n",
    "        heartrate = row['heartrate']\n",
    "        watts = row['watts']\n",
    "\n",
    "        mask = [w is not None for w in watts]  # Create a mask for non-None values\n",
    "        watts_valid = [w for w, m in zip(watts, mask) if m]\n",
    "        heartrate_valid = [h for h, m in zip(heartrate, mask) if m]\n",
    "\n",
    "        X_train.extend([[x] for x in heartrate_valid])\n",
    "        y_train.extend([[y] for y in watts_valid])\n",
    "\n",
    "    # Perform polynomial regression\n",
    "    poly_features = PolynomialFeatures(degree=degree)\n",
    "    X_poly = poly_features.fit_transform(X_train)\n",
    "\n",
    "    regressor = LinearRegression()\n",
    "    regressor.fit(X_poly, y_train)\n",
    "\n",
    "    # Fill the missing values\n",
    "    for idx, row in df.iterrows():\n",
    "        heartrate = row['heartrate']\n",
    "        watts = row['watts']\n",
    "\n",
    "        mask = [w is None or w == 0 for w in watts]  # Create a mask for None and 0 values\n",
    "\n",
    "        if any(mask):\n",
    "            heartrate_fill = [h for h, m in zip(heartrate, mask) if m]\n",
    "            X_test = poly_features.transform([[x] for x in heartrate_fill])\n",
    "            watts_fill = regressor.predict(X_test)\n",
    "\n",
    "            # Replace the None and 0 values with the predicted values\n",
    "            for i, value in enumerate(watts_fill):\n",
    "                if watts[i] is None or watts[i] == 0:\n",
    "                    watts[i] = value\n",
    "\n",
    "            watts_flat = flatten_list(watts)\n",
    "            watts_flat = convert_arrays_to_lists(watts_flat)\n",
    "            df.at[idx, 'watts'] = watts_flat\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "ad_filled = fill_none_with_regression(athletic_data, degree=2)\n",
    "print(ad_filled)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-05T00:00:27.159991Z",
     "start_time": "2023-06-05T00:00:15.364511Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# NOISE REDUCTION : Using Kalman Filtering Technique"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pykalman import KalmanFilter\n",
    "\n",
    "def reduce_noise_kalman(data):\n",
    "    kf = KalmanFilter(transition_matrices=[1],\n",
    "                      observation_matrices=[1],\n",
    "                      initial_state_mean=data[0],\n",
    "                      initial_state_covariance=1,\n",
    "                      observation_covariance=1,\n",
    "                      transition_covariance=0.1)\n",
    "\n",
    "    filtered_state_means, filtered_state_covariances = kf.filter(data)\n",
    "\n",
    "    return filtered_state_means\n",
    "\n",
    "athletic_data['heartrate'] = athletic_data['heartrate'].apply(reduce_noise_kalman)\n",
    "athletic_data['watts'] = athletic_data['watts'].apply(reduce_noise_kalman)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA DOWNSAMPLING : A data aggregation procedure where we decreasing the time-frequency of the data to plot on graph and visualise easily with less variations and minimizing abundance of values to process, making machine learning algorithms work faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to downsample a column with None values\n",
    "def downsample_column(arr, factor):\n",
    "    downsampled_arr = []\n",
    "    for i in range(0, len(arr), factor):\n",
    "        segment = arr[i:i+factor]  # Extract a segment of the array based on the downsampling factor\n",
    "        non_none_values = [value for value in segment if value is not None]  # Filter out None values\n",
    "        if non_none_values:\n",
    "            downsampled_arr.append(sum(non_none_values) / len(non_none_values))  # Calculate the average of non-None values\n",
    "        else:\n",
    "            downsampled_arr.append(None)  # Assign None if all values in the segment are None\n",
    "    return downsampled_arr\n",
    "\n",
    "\n",
    "athletic_data['heartrate'] = athletic_data['heartrate'].apply(lambda arr: downsample_column(arr,200))\n",
    "athletic_data['watts'] = athletic_data['watts'].apply(lambda arr: downsample_column(arr,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

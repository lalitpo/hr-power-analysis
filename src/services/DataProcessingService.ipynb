{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve all the relevant data from the table athletic-data in the database.\n",
    "# Pre-requisite :\n",
    "  1. Activity has to be of more than 2hrs.\n",
    "  2. Watts and HeartRate column should not be null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-02T21:26:24.466809Z",
     "start_time": "2023-06-02T21:26:15.707009Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.repositories.PowerAndHRRepository import *\n",
    "\n",
    "athletic_data_db = get_athletic_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PROFILING/FILTERING : Removing irrelevant columns not required for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-02T21:26:25.766722Z",
     "start_time": "2023-06-02T21:26:25.757121Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_to_ignore = configs.get(\"ignore-columns\").data\n",
    "athletic_data = athletic_data_db.drop(cols_to_ignore.split(\",\"), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA DOWNSAMPLING : A data aggregation procedure where we decreasing the time-frequency of the data to plot on graph and visualise easily with less variations and minimizing abundance of values to process making machine learning algorithms working faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-02T21:26:55.455563Z",
     "start_time": "2023-06-02T21:26:55.213580Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Function to downsample a column with None values\n",
    "def downsample_column(arr, factor):\n",
    "    downsampled_arr = []\n",
    "    for i in range(0, len(arr), factor):\n",
    "        segment = arr[i:i+factor]  # Extract a segment of the array based on the downsampling factor\n",
    "        non_none_values = [value for value in segment if value is not None]  # Filter out None values\n",
    "        if non_none_values:\n",
    "            downsampled_arr.append(sum(non_none_values) / len(non_none_values))  # Calculate the average of non-None values\n",
    "        else:\n",
    "            downsampled_arr.append(None)  # Assign None if all values in the segment are None\n",
    "    return downsampled_arr\n",
    "\n",
    "\n",
    "athletic_data['heartrate'] = athletic_data['heartrate'].apply(lambda arr: downsample_column(arr,200))\n",
    "athletic_data['watts'] = athletic_data['watts'].apply(lambda arr: downsample_column(arr,200))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve all the relevant data from the table athletic-data in the database.\n",
    "# Pre-requisite :\n",
    "  1. Activity has to be of more than 2hrs.\n",
    "  2. Watts and HeartRate column should not be null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T17:06:56.279870Z",
     "start_time": "2023-06-06T17:06:48.942456Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are successfully connected to your Database!\n"
     ]
    }
   ],
   "source": [
    "from src.repositories.PowerAndHRRepository import *\n",
    "\n",
    "athletic_data_db = get_athletic_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PROFILING : Removing irrelevant columns not required for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T17:07:32.261657Z",
     "start_time": "2023-06-06T17:07:32.254629Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_to_ignore = configs.get(\"ignore-columns\").data\n",
    "athletic_data = athletic_data_db.drop(cols_to_ignore.split(\",\"), axis=1).rename(columns={'Power (in watts)' : 'power'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# NA/NONE CHECK : Checking if watts or heartrate column contains null values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/164 entries contains NA/NONE/null in heartrate\n",
      "147/164  entries contains NA/NONE/null in Power\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hr_contains_none = athletic_data['heartrate'].apply(lambda x: any(item is None for item in x) if x is not None else False).sum()\n",
    "print(f\"{hr_contains_none}/{len(athletic_data['heartrate'])} entries contains NA/NONE/null in heartrate\")\n",
    "watts_contains_none =  athletic_data['power'].apply(lambda x: any(item is None for item in x) if x is not None else False).sum()\n",
    "print(f\"{watts_contains_none}/{len(athletic_data['power'])}  entries contains NA/NONE/null in Power\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T17:07:34.484579Z",
     "start_time": "2023-06-06T17:07:34.341808Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LINEAR INTERPOLATION For Missing Data in Power(watts):\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def interpolate_power(lst):\n",
    "    interpolated_lst = []\n",
    "    x = []\n",
    "    y = []\n",
    "    for i, val in enumerate(lst):\n",
    "        if val is None:\n",
    "            x.append(i)\n",
    "        else:\n",
    "            y.append(val)\n",
    "            if len(x) > 0:\n",
    "                interpolated_y = np.interp(x, [x[0] - 1, i], [y[0], val])\n",
    "                interpolated_lst.extend(interpolated_y)\n",
    "                x = []\n",
    "                y = []\n",
    "                interpolated_lst.append(val)\n",
    "            else:\n",
    "                interpolated_lst.append(val)\n",
    "    return interpolated_lst\n",
    "\n",
    "\n",
    "athletic_data['power'] = athletic_data['power'].apply(interpolate_power)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T17:07:36.926559Z",
     "start_time": "2023-06-06T17:07:36.497238Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# NON-LINEAR/POLYNOMIAL REGRESSION For Missing Data :\n",
    "#1. Power output/watts has similar variations as heartrate and heartrate has no missing entries(so model can rely on heartrate as the attribute to understand variations for watts and fill missing values.\n",
    "#2. Power Output changes gradually on change of heart rate, not instantaneously.\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import numpy as np\n",
    "\n",
    "def flatten_list(lst):\n",
    "    flattened = []\n",
    "    for item in lst:\n",
    "        if isinstance(item, (list, tuple)):\n",
    "            flattened.extend(flatten_list(item))\n",
    "        else:\n",
    "            flattened.append(item)\n",
    "    return flattened\n",
    "\n",
    "def convert_arrays_to_lists(arr):\n",
    "    converted = []\n",
    "    for item in arr:\n",
    "        if isinstance(item, np.ndarray):\n",
    "            converted.append(item.tolist())\n",
    "        elif isinstance(item, (list, tuple)):\n",
    "            converted.append(convert_arrays_to_lists(item))\n",
    "        else:\n",
    "            converted.append(item)\n",
    "    return converted\n",
    "\n",
    "def fill_none_with_regression(df, degree=2):\n",
    "    df_copy = df.copy()\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    # Prepare the training data\n",
    "    for idx, row in df_copy.iterrows():\n",
    "        heartrate = row['heartrate']\n",
    "        watts = row['watts']\n",
    "        mask = [w is not None for w in watts]  # Create a mask for non-None values\n",
    "        watts_valid = np.array(watts)[mask]\n",
    "        heartrate_valid = np.array(heartrate)[mask]\n",
    "        X_train.extend([[x] for x in heartrate_valid])\n",
    "        y_train.extend([[y] for y in watts_valid])\n",
    "    # Perform polynomial regression\n",
    "    poly_features = PolynomialFeatures(degree=degree)\n",
    "    X_poly = poly_features.fit_transform(X_train)\n",
    "    regressor = LinearRegression()\n",
    "    regressor.fit(X_poly, y_train)\n",
    "    # Fill the missing values\n",
    "    for idx, row in df.iterrows():\n",
    "        heartrate = row['heartrate']\n",
    "        watts = row['watts']\n",
    "        mask = [w is None or w == 0 for w in watts]  # Create a mask for None and 0 values\n",
    "        if any(mask):\n",
    "            heartrate_fill = np.array(heartrate)[mask].reshape(-1, 1)\n",
    "            X_test = poly_features.transform(heartrate_fill)\n",
    "            watts_fill = regressor.predict(X_test)\n",
    "            # Replace the None and 0 values with the predicted values\n",
    "            for i, value in enumerate(watts_fill):\n",
    "                if watts[i] is None or watts[i] == 0:\n",
    "                    watts[i] = value\n",
    "            # Flatten the list of watts and convert arrays to lists\n",
    "            watts_flat = flatten_list(watts)\n",
    "            watts_flat = convert_arrays_to_lists(watts_flat)\n",
    "            df.at[idx, 'watts'] = watts_flat\n",
    "    return df\n",
    "ad_filled = fill_none_with_regression(athletic_data, degree=2)\n",
    "print(ad_filled)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# NOISE REDUCTION : Using Kalman Filtering Technique\n",
    "\n",
    "from pykalman import KalmanFilter\n",
    "\n",
    "def reduce_noise_kalman(data):\n",
    "    kf = KalmanFilter(transition_matrices=[1],\n",
    "                      observation_matrices=[1],\n",
    "                      initial_state_mean=data[0],\n",
    "                      initial_state_covariance=1,\n",
    "                      observation_covariance=1,\n",
    "                      transition_covariance=0.1)\n",
    "\n",
    "    filtered_state_means, filtered_state_covariances = kf.filter(data)\n",
    "\n",
    "    return filtered_state_means\n",
    "\n",
    "athletic_data['heartrate'] = athletic_data['heartrate'].apply(reduce_noise_kalman)\n",
    "athletic_data['watts'] = athletic_data['watts'].apply(reduce_noise_kalman)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DATA DOWNSAMPLING : A data aggregation procedure where we decreasing the time-frequency of the data to plot on graph and visualise easily with less variations and minimizing abundance of values to process, making machine learning algorithms work faster.\n",
    "\n",
    "# Function to downsample a column with None values\n",
    "def downsample_column(arr, factor):\n",
    "    downsampled_arr = []\n",
    "    for i in range(0, len(arr), factor):\n",
    "        segment = arr[i:i+factor]  # Extract a segment of the array based on the downsampling factor\n",
    "        non_none_values = [value for value in segment if value is not None]  # Filter out None values\n",
    "        if non_none_values:\n",
    "            downsampled_arr.append(sum(non_none_values) / len(non_none_values))  # Calculate the average of non-None values\n",
    "        else:\n",
    "            downsampled_arr.append(None)  # Assign None if all values in the segment are None\n",
    "    return downsampled_arr\n",
    "\n",
    "\n",
    "athletic_data['heartrate'] = athletic_data['heartrate'].apply(lambda arr: downsample_column(arr,200))\n",
    "athletic_data['power'] = athletic_data['power'].apply(lambda arr: downsample_column(arr,200))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Saving Preprocessed DataSet : athletic_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'athletic_data' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "%store athletic_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T19:11:44.352468Z",
     "start_time": "2023-06-06T19:11:44.182615Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
